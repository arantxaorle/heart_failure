{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\arant\\appdata\\roaming\\python\\python310\\site-packages (0.12.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\arant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (3.6.0)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\arant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\arant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.23.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\arant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\arant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\arant\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\arant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\arant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.37.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\arant\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\arant\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\arant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.25->seaborn) (2022.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arant\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install seaborn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os.path import dirname, abspath\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PIPELINE_SWITCH': {'PIPELINE_TEST': False}, 'FEATURE_SET_VARS': {'IMPUTATION': 'Linear', 'MIN_THRESHOLD': 5}, 'FOLDERS': {'DATA': 'data', 'RAW_FEATURESET': 'raw_featureset', 'TEMPORAL': 'temporal_data', 'POST_PROCESSED_TRAIN_SET': 'post_processed_featureset', 'POST_PROCESSED_TEST_SET': 'post_processed_testset'}, 'FEATURE_SET': {'RAW_FEATURESET_EXCEL': 'Datos.xlsx', 'SPLIT_LABEL_NAME': 'HeartDisease', 'FEATURESET_EXCEL': 'Data_featureset.xlsx', 'LABELS_EXCEL': 'Data_labelset.xlsx', 'FEATURES_TRAIN': 'Train_featureset.xlsx', 'FEATURES_TEST': 'Test_featureset.xlsx', 'LABELS_TRAIN': 'Train_labelset.xlsx', 'LABELS_TEST': 'Test_labelset.xlsx', 'POST_PROCESSED_TRAIN_EXCEL': 'Post_processed_train_featureset.xlsx', 'POST_PROCESSED_TEST_EXCEL': 'Post_processed_test_featureset.xlsx', 'POSTPROCESSING_STEPS': {'STANDARDIZATION': True, 'NORMALIZATION': False, 'ONE_HOT_ENCODING': True}}}\n"
     ]
    }
   ],
   "source": [
    "from config import config_variables\n",
    "print(config_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeartDataFile(object):\n",
    "    def __init__(self, config_variables):\n",
    "        self.config = config_variables\n",
    "        self.base_path = (abspath(os.getcwd()))\n",
    "\n",
    "        self.data_folder = config_variables['FOLDERS']['DATA']\n",
    "        self.raw_data_folder = config_variables['FOLDERS']['RAW_FEATURESET']\n",
    "        self.raw_excel_file = config_variables['FEATURE_SET']['RAW_FEATURESET_EXCEL']\n",
    "        self.path_input_excel = os.path.join(self.base_path, self.data_folder, self.raw_data_folder, self.raw_excel_file)\n",
    "        self.raw_heart_df = pd.read_excel(self.path_input_excel)\n",
    "\n",
    "        self.temporal_data_folder = config_variables['FOLDERS']['TEMPORAL']\n",
    "        self.label_name = config_variables['FEATURE_SET']['SPLIT_LABEL_NAME']\n",
    "        self.target_name = config_variables['FEATURE_SET']['SPLIT_LABEL_NAME']\n",
    "\n",
    "\n",
    "        self.feature_file = config_variables['FEATURE_SET']['FEATURESET_EXCEL']\n",
    "        self.output_feature_file = os.path.join(self.base_path, self.data_folder, self.temporal_data_folder, self.feature_file)\n",
    "        #self.feature = pd.read_excel(self.output_feature_file)\n",
    "  \n",
    "        self.label_file = config_variables['FEATURE_SET']['LABELS_EXCEL']\n",
    "        self.output_label_file = os.path.join(self.base_path, self.data_folder, self.temporal_data_folder, self.label_file)\n",
    "        #self.label = pd.read_excel(self.output_label_file)\n",
    "        \n",
    "\n",
    "        self.train_features = config_variables ['FEATURE_SET']['FEATURES_TRAIN']\n",
    "        self.output_train_features = os.path.join(self.base_path, self.data_folder, self.temporal_data_folder, self.train_features)\n",
    "        self.test_features = config_variables ['FEATURE_SET']['FEATURES_TEST']\n",
    "        self.output_test_features = os.path.join(self.base_path, self.data_folder, self.temporal_data_folder, self.test_features)\n",
    "\n",
    "        self.train_label = config_variables ['FEATURE_SET']['LABELS_TRAIN']\n",
    "        self.output_train_label = os.path.join(self.base_path, self.data_folder, self.temporal_data_folder, self.train_label)\n",
    "        self.test_label = config_variables ['FEATURE_SET']['LABELS_TEST']\n",
    "        self.output_test_label = os.path.join(self.base_path, self.data_folder, self.temporal_data_folder, self.test_label)\n",
    "        \n",
    "    \n",
    "        self.post_train_data_folder = config_variables['FOLDERS']['POST_PROCESSED_TRAIN_SET']\n",
    "        self.post_test_data_folder = config_variables['FOLDERS']['POST_PROCESSED_TEST_SET']\n",
    "\n",
    "        self.post_processed_train_set_excel_file = config_variables['FEATURE_SET']['POST_PROCESSED_TRAIN_EXCEL']\n",
    "        self.post_processed_test_set_excel_file = config_variables['FEATURE_SET']['POST_PROCESSED_TEST_EXCEL']\n",
    "        self.train_set_output_excel = os.path.join(self.base_path, self.data_folder, self.post_train_data_folder, self.post_processed_train_set_excel_file)\n",
    "        self.test_set_output_excel = os.path.join(self.base_path, self.data_folder, self.post_test_data_folder, self.post_processed_test_set_excel_file)\n",
    "\n",
    "\n",
    "    \n",
    "    def split_labels_target(self, config_variables):\n",
    "\n",
    "         #Check if folder exists\n",
    "        if os.path.exists(os.path.join(self.base_path, self.data_folder, self.temporal_data_folder)) == False:\n",
    "            #Create folder\n",
    "            os.mkdir(os.path.join(self.base_path, self.data_folder, self.temporal_data_folder))\n",
    "        else:\n",
    "             print('Folder already exists')\n",
    "        \n",
    "        #Check if featureset file exists \n",
    "        if os.path.exists(os.path.join(self.base_path, self.data_folder, self.temporal_data_folder, self.output_feature_file)) == True:\n",
    "            print('Feature set file already exists')\n",
    "        \n",
    "        else: \n",
    "            self.feature_set = self.raw_heart_df.loc[:, self.raw_heart_df.columns != self.label_name]\n",
    "            self.feature_df = self.feature_set.to_excel(self.output_feature_file, index=False)\n",
    "\n",
    "        #Check if label file exists \n",
    "        if os.path.exists(os.path.join(self.base_path, self.data_folder, self.temporal_data_folder, self.output_label_file)) == True:\n",
    "            print('Label set file already exists')\n",
    "        else: \n",
    "            self.label_set = self.raw_heart_df[self.label_name]\n",
    "            self.label_df = self.label_set.to_excel(self.output_label_file, index=False)\n",
    "\n",
    "        \n",
    "    def split_train_test(self, config_variables):\n",
    "        #This function is considering stratification \n",
    "        self.feature = pd.read_excel(self.output_feature_file)\n",
    "        self.label = pd.read_excel(self.output_label_file)\n",
    "\n",
    "        X = self.feature\n",
    "        y = self.label\n",
    "\n",
    "        #How to call these variables\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100, stratify=y)\n",
    "        \n",
    "\n",
    "        if os.path.exists(os.path.join(self.base_path, self.data_folder, self.temporal_data_folder, self.output_train_features)) == True:\n",
    "            print('Features trainset already exists')\n",
    "        else:\n",
    "            X_train.to_excel(self.output_train_features, index=False)\n",
    "        \n",
    "        if os.path.exists(os.path.join(self.base_path, self.data_folder, self.temporal_data_folder, self.output_test_features)) == True:\n",
    "            print('Features testset already exists')    \n",
    "        else:\n",
    "            X_test.to_excel(self.output_test_features, index=False) \n",
    "        \n",
    "        if os.path.exists(os.path.join(self.base_path, self.data_folder, self.temporal_data_folder, self.output_train_label)) == True:\n",
    "            print('Label trainset already exists')\n",
    "        else:\n",
    "            y_train.to_excel(self.output_train_label, index=False)        \n",
    "        \n",
    "        if os.path.exists(os.path.join(self.base_path, self.data_folder, self.temporal_data_folder, self.output_test_label)) == True:\n",
    "            print('Label testset already exists')\n",
    "        else:\n",
    "            y_test.to_excel(self.output_test_label, index=False) \n",
    "    \n",
    "\n",
    "\n",
    "    def visualization_num(self, config_variables):\n",
    "      \n",
    "        #Im only reading the features of the training set \n",
    "        self.feature_heart_df = pd.read_excel(self.output_train_features)\n",
    "\n",
    "        #Define numerical variables of dataframe \n",
    "        numeric = self.feature_heart_df.select_dtypes(include=[np.number])\n",
    "        #Delete first column that is number of patients\n",
    "        numeric_heart  = numeric.iloc[: , 1:]\n",
    "\n",
    "        # Get seaborn plot 1\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        heatmap = sns.heatmap(numeric_heart.corr(),  cmap = 'coolwarm', vmin=-1, vmax=1, annot=True)\n",
    "\n",
    "        heatmap.set_title('Correlation plot', fontdict={'fontsize':12}, pad=12)\n",
    "\n",
    "        plt.savefig('plot.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        #Make boxplot for numerical features \n",
    "        red_circle = dict(markerfacecolor='red', marker='o', markeredgecolor='white')\n",
    "        fig, axs = plt.subplots(1, len(numeric_heart.columns), figsize=(20,10))\n",
    "        for i, ax in enumerate(axs.flat):\n",
    "            ax.boxplot(numeric_heart.iloc[:,i], flierprops=red_circle)\n",
    "            ax.set_title(numeric_heart.columns[i], fontsize=20, fontweight='bold')\n",
    "            ax.tick_params(axis='y', labelsize=14)\n",
    "            plt.tight_layout()\n",
    "\n",
    "        \n",
    "        #Save it in a specific path \n",
    "        plt.savefig('boxplot.png')\n",
    "\n",
    "    def visualization_cat(self, config_variables):\n",
    "      \n",
    "        #Im only reading the features of the training set \n",
    "        self.feature_heart_df = pd.read_excel(self.output_train_features)\n",
    "\n",
    "\n",
    "        categorical_heart = self.feature_heart_df.select_dtypes(exclude=[np.number])\n",
    "        for categorical_columns in categorical_heart.columns.to_list():\n",
    "            plt.figure()\n",
    "            sns.countplot(y=categorical_columns, data=categorical_heart, palette=\"husl\")\n",
    "            plt.show()\n",
    "              \n",
    "\n",
    "    def standardization(self, train_df, test_df, integer_features):\n",
    "\n",
    "        transformer_std = ColumnTransformer([(\"num\", StandardScaler(), integer_features)]) \n",
    "        \n",
    "        #Apply std to the train set \n",
    "        transformed_std_train = transformer_std.fit_transform(train_df)\n",
    "        \n",
    "        #Apply std to the test set \n",
    "        transformed_std_test = transformer_std.transform(test_df)\n",
    "        \n",
    "        std_train_df = pd.DataFrame(transformed_std_train, columns=transformer_std.get_feature_names_out())\n",
    "        std_test_df = pd.DataFrame(transformed_std_test, columns=transformer_std.get_feature_names_out())\n",
    "\n",
    "        return std_train_df, std_test_df\n",
    "\n",
    "    \n",
    "    def normalization(self, train_df, test_df, integer_features):    \n",
    "\n",
    "        transformer_norm = ColumnTransformer([(\"num\", MinMaxScaler(), integer_features)]) \n",
    "        transformed_norm = transformer_norm.fit_transform(df)\n",
    "        norm_df = pd.DataFrame(transformed_norm, columns=transformer_norm.get_feature_names_out())\n",
    "    \n",
    "        return norm_df\n",
    "\n",
    "    def one_hot_encoding(self, train_df, test_df, categorical_features):\n",
    "\n",
    "        transformer_ohe = ColumnTransformer([(\"cat\", OneHotEncoder(), categorical_features)])\n",
    "        \n",
    "        #Not sure about this line\n",
    "        #transformer_train_ohe = ColumnTransformer([(\"cat\", OneHotEncoder(), categorical_features)])\n",
    "        \n",
    "        transformed_ohe_train = transformer_ohe.fit_transform(train_df)\n",
    "        transformed_ohe_test = transformer_ohe.transform(test_df)\n",
    "\n",
    "        ohe_train_df = pd.DataFrame(transformed_ohe_train, columns=transformer_ohe.get_feature_names_out())\n",
    "        ohe_test_df = pd.DataFrame(transformed_ohe_test, columns=transformer_ohe.get_feature_names_out())\n",
    "\n",
    "        #print(ohe_test_df)\n",
    "        return ohe_train_df, ohe_test_df\n",
    "\n",
    "   \n",
    "        #Univariate feature selection \n",
    "    def univariate_selection(self, ):\n",
    "        X = data.iloc[:,0:18]  #independent columns\n",
    "        y = data.iloc[:,19]    #target column i.e price range\n",
    "        #apply SelectKBest class to extract top 10 best features\n",
    "        bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "        fit = bestfeatures.fit(X,y)\n",
    "        dfscores = pd.DataFrame(fit.scores_)\n",
    "        dfcolumns = pd.DataFrame(X.columns)\n",
    "        #concat two dataframes for better visualization \n",
    "        featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "        featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "        print(featureScores.nlargest(10,'Score'))  #print 10 best features\n",
    "        \n",
    "    def build_featureset_definitive(self, df):\n",
    "        #Check if featureset exists\n",
    "        if os.path.exists(self.train_set_output_excel) == False:\n",
    "            #Check if folder exists\n",
    "            if os.path.exists(os.path.join(self.base_path, self.data_folder, self.post_train_data_folder)) == False:\n",
    "                #Create folder\n",
    "                os.mkdir(os.path.join(self.base_path, self.data_folder, self.post_train_data_folder))\n",
    "        \n",
    "            #Check if featureset exists\n",
    "        if os.path.exists(self.test_set_output_excel) == False:\n",
    "            #Check if folder exists\n",
    "            if os.path.exists(os.path.join(self.base_path, self.data_folder, self.post_test_data_folder)) == False:\n",
    "                #Create folder\n",
    "                os.mkdir(os.path.join(self.base_path, self.data_folder, self.post_test_data_folder))\n",
    "\n",
    "            #Load input featureset\n",
    "            train_df = pd.read_excel(self.output_train_features)\n",
    "            test_df = pd.read_excel(self.output_test_features)\n",
    "            \n",
    "            integer_features = train_df.select_dtypes(exclude=\"object\").columns\n",
    "            #integer_test_features = test_df.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "            #print(integer_features)\n",
    "            categorical_features = train_df.select_dtypes(include=\"object\").columns\n",
    "            #print(categorical_features)\n",
    "\n",
    "\n",
    "            final_train_df = pd.DataFrame()\n",
    "            final_test_df = pd.DataFrame()\n",
    "            \n",
    "            #Preprocessing steps\n",
    "            if self.config['FEATURE_SET']['POSTPROCESSING_STEPS']['STANDARDIZATION']:\n",
    "                std_train_df, std_test_df = self.standardization(train_df, test_df, integer_features)\n",
    "                if len(final_train_df) == 0:\n",
    "                    print(len(std_train_df))\n",
    "                    print(len(std_test_df))\n",
    "                    final_train_df = std_train_df\n",
    "                    final_test_df = std_test_df\n",
    "                else:\n",
    "                    final_train_df = final_train_df.join(std_train_df)\n",
    "                    final_test_df = final_test_df.join(std_test_df)\n",
    "\n",
    "            if self.config['FEATURE_SET']['POSTPROCESSING_STEPS']['NORMALIZATION']:\n",
    "                train_df, test_df = self.normalization(train_df, integer_features)\n",
    "\n",
    "            if self.config['FEATURE_SET']['POSTPROCESSING_STEPS']['ONE_HOT_ENCODING']:\n",
    "                ohe_train_df, ohe_test_df = self.one_hot_encoding(train_df, test_df, categorical_features)\n",
    "                if len(final_train_df) == 0:\n",
    "                    final_train_df = ohe_train_df\n",
    "                    final_test_df = ohe_test_df\n",
    "                else:\n",
    "                    print(len(ohe_train_df))\n",
    "                    print(len(ohe_test_df))\n",
    "                    final_train_df = final_train_df.join(ohe_train_df)\n",
    "                    final_test_df = final_test_df.join(ohe_test_df)\n",
    "         \n",
    "            #Save postprocessed featureset \n",
    "            \n",
    "            final_train_df.to_excel(self.test_set_output_excel, index=False)\n",
    "            final_test_df.to_excel(self.train_set_output_excel, index=False)\n",
    "\n",
    "          \n",
    "        else: \n",
    "            print('No need to build train and file featureset, file already exists')\n",
    "            \n",
    "    def classification_report(y_test, y_pred):\n",
    "        \n",
    "        report = metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "        df_classification_report = pd.DataFrame(report).transpose()\n",
    "        df_classification_report = df_classification_report.sort_values\n",
    "        df_classification_report.to_excel(\"results.xlsx\")\n",
    "        return df_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartdata = HeartDataFile(config_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists\n",
      "Feature set file already exists\n",
      "Label set file already exists\n"
     ]
    }
   ],
   "source": [
    "heartdata.split_labels_target(config_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features trainset already exists\n",
      "Features testset already exists\n",
      "Label trainset already exists\n",
      "Label testset already exists\n"
     ]
    }
   ],
   "source": [
    "heartdata.split_train_test(config_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartdata.visualization_cat(config_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartdata.visualization_num(config_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No need to build featureset, file already exists\n"
     ]
    }
   ],
   "source": [
    "heartdata.build_featureset_definitive(config_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "777a9d555769d94f8b34f8532681f098915e1e0d5bac5997fe5ed84cae912a97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
